{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpt7gEAQ8thUpvKC9Da662",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohaammed-Fouad/Ligand-Based-Virtual-Screening/blob/main/VIRTUAL_SCREENING_SPRINT_SCRIPT_(SMILES).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja400gcv6I8M"
      },
      "outputs": [],
      "source": [
        "# ==========================================================\n",
        "# VIRTUAL SCREENING SPRINT SCRIPT (SMILES)\n",
        "# SELECTION COUNT: 500\n",
        "# OUTPUTS: .smi, .xlsx, .txt, PhysChem .xlsx, and Filtered .xlsx\n",
        "# ==========================================================\n",
        "# 1. INSTALLATION & SETUP\n",
        "\n",
        "!pip install rdkit pandas tqdm openpyxl\n",
        "from google.colab import drive, files\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, DataStructs, Draw, Descriptors, rdMolDescriptors\n",
        "from rdkit.ML.Cluster import Butina\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Mount Google Drive for persistent backup\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    SAVE_TO_DRIVE = True\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Drive not mounted. Results will only be saved locally.\")\n",
        "    SAVE_TO_DRIVE = False\n",
        "\n",
        "def calculate_physchem(mol):\n",
        "    \"\"\"Calculates comprehensive physicochemical properties.\"\"\"\n",
        "    mw = Descriptors.MolWt(mol)\n",
        "    logp = Descriptors.MolLogP(mol)\n",
        "    hbd = rdMolDescriptors.CalcNumHBD(mol)\n",
        "    hba = rdMolDescriptors.CalcNumHBA(mol)\n",
        "    tpsa = Descriptors.TPSA(mol)\n",
        "    rb = rdMolDescriptors.CalcNumRotatableBonds(mol)\n",
        "\n",
        "    # Lipinski's Rule of Five\n",
        "    lipinski = (mw <= 500 and logp <= 5 and hbd <= 5 and hba <= 10)\n",
        "\n",
        "    # Lead-like / Veber Criteria (Good oral bioavailability & permeability)\n",
        "    lead_like = (lipinski and rb <= 10 and tpsa <= 140)\n",
        "\n",
        "    return {\n",
        "        'MW': round(mw, 2),\n",
        "        'LogP': round(logp, 2),\n",
        "        'HBD': hbd,\n",
        "        'HBA': hba,\n",
        "        'TPSA': round(tpsa, 2),\n",
        "        'Rotatable_Bonds': rb,\n",
        "        'Lipinski_Pass': lipinski,\n",
        "        'Lead_Like_Pass': lead_like\n",
        "    }\n",
        "\n",
        "def load_uploaded_smi(prompt_text):\n",
        "    \"\"\"Triggers upload and processes the SMILES file.\"\"\"\n",
        "    print(f\"\\n--- {prompt_text} ---\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        return None, None\n",
        "\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    content = uploaded[filename]\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(io.BytesIO(content), sep=None, engine='python')\n",
        "        smiles_col = [c for c in df.columns if 'smiles' in c.lower()]\n",
        "        smiles_col = smiles_col[0] if smiles_col else df.columns[0]\n",
        "\n",
        "        mols = []\n",
        "        for idx, row in df.iterrows():\n",
        "            m = Chem.MolFromSmiles(str(row[smiles_col]))\n",
        "            if m:\n",
        "                name = str(row[df.columns[1]]) if len(df.columns) > 1 else f\"ID_{idx}\"\n",
        "                m.SetProp(\"_Name\", name)\n",
        "                mols.append(m)\n",
        "\n",
        "        print(f\"‚úÖ Loaded {len(mols)} valid molecules.\")\n",
        "        return mols, filename\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error parsing file: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# --- STEP 1: UPLOAD DATA ---\n",
        "known_mols, _ = load_uploaded_smi(\"STEP 1: UPLOAD KNOWN ACTIVES\")\n",
        "if known_mols:\n",
        "    known_fps = [AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048) for m in known_mols]\n",
        "    blind_mols, _ = load_uploaded_smi(\"STEP 2: UPLOAD BLIND DATASET\")\n",
        "\n",
        "    if blind_mols:\n",
        "        # --- STEP 2: SIMILARITY SEARCH ---\n",
        "        print(\"\\nSTEP 3: Running Tanimoto Similarity Search...\")\n",
        "        blind_results = []\n",
        "        for m in tqdm(blind_mols):\n",
        "            fp = AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048)\n",
        "            sims = DataStructs.BulkTanimotoSimilarity(fp, known_fps)\n",
        "            max_s = max(sims)\n",
        "            blind_results.append({\n",
        "                'SMILES': Chem.MolToSmiles(m),\n",
        "                'ID': m.GetProp(\"_Name\"),\n",
        "                'mol_obj': m,\n",
        "                'fp': fp,\n",
        "                'similarity': max_s\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(blind_results)\n",
        "        df = df.sort_values(by='similarity', ascending=False).reset_index(drop=True)\n",
        "\n",
        "        # --- STEP 3: DIVERSITY CLUSTERING ---\n",
        "        print(\"\\nSTEP 4: Selecting 500 Diverse Candidates...\")\n",
        "        top_pool = df.head(1000).copy()\n",
        "        fps_to_cluster = list(top_pool['fp'])\n",
        "\n",
        "        dists = []\n",
        "        nfps = len(fps_to_cluster)\n",
        "        for i in range(1, nfps):\n",
        "            sims = DataStructs.BulkTanimotoSimilarity(fps_to_cluster[i], fps_to_cluster[:i])\n",
        "            dists.extend([1-x for x in sims])\n",
        "\n",
        "        clusters = Butina.ClusterData(dists, nfps, 0.35, isDistData=True)\n",
        "        selected_indices = []\n",
        "        for cluster in clusters:\n",
        "            selected_indices.append(cluster[0])\n",
        "            if len(selected_indices) == 500: break\n",
        "\n",
        "        if len(selected_indices) < 500:\n",
        "            already_picked = set(selected_indices)\n",
        "            for i in range(len(top_pool)):\n",
        "                if i not in already_picked:\n",
        "                    selected_indices.append(i)\n",
        "                if len(selected_indices) == 500: break\n",
        "\n",
        "        final_selection = top_pool.iloc[selected_indices].copy()\n",
        "\n",
        "        # --- STEP 4: PHYSICOCHEMICAL ANALYSIS ---\n",
        "        print(\"\\nSTEP 5: Calculating Properties & Filtering Lead-Like Hits...\")\n",
        "        physchem_list = []\n",
        "        for m in final_selection['mol_obj']:\n",
        "            physchem_list.append(calculate_physchem(m))\n",
        "\n",
        "        physchem_df = pd.DataFrame(physchem_list)\n",
        "        extended_df = pd.concat([final_selection.reset_index(drop=True), physchem_df], axis=1)\n",
        "        extended_df = extended_df.drop(columns=['mol_obj', 'fp'])\n",
        "\n",
        "        # --- STEP 5: CREATE THE FOURTH FILTERED FILE ---\n",
        "        # Filters for only those that pass Lead_Like criteria\n",
        "        lead_hits_df = extended_df[extended_df['Lead_Like_Pass'] == True].copy()\n",
        "\n",
        "        # --- STEP 6: EXPORT ALL FILES ---\n",
        "        excel_fn = \"final_500_selection.xlsx\"\n",
        "        physchem_fn = \"final_500_physchem_full.xlsx\"\n",
        "        filtered_fn = \"final_top_lead_like_hits.xlsx\"\n",
        "        txt_fn = \"selection_summary_500.txt\"\n",
        "\n",
        "        # Export Excel Files\n",
        "        final_selection[['SMILES', 'ID', 'similarity']].to_excel(excel_fn, index=False)\n",
        "        extended_df.to_excel(physchem_fn, index=False)\n",
        "        lead_hits_df.to_excel(filtered_fn, index=False)\n",
        "\n",
        "        # Export Text Summary\n",
        "        with open(txt_fn, 'w') as f:\n",
        "            f.write(\"=== VIRTUAL SCREENING SUMMARY (TOP 500) ===\\n\")\n",
        "            f.write(f\"Total Initial Pool: {len(extended_df)}\\n\")\n",
        "            f.write(f\"Lead-Like Hits (Filtered): {len(lead_hits_df)}\\n\")\n",
        "            f.write(f\"Lipinski Pass Rate: {(extended_df['Lipinski_Pass'].sum()/500)*100:.1f}%\\n\\n\")\n",
        "            f.write(extended_df[['ID', 'similarity', 'MW', 'LogP', 'Lead_Like_Pass']].head(20).to_string(index=False))\n",
        "\n",
        "        # Backup to Drive\n",
        "        if SAVE_TO_DRIVE:\n",
        "            for d, name in [(extended_df, physchem_fn), (lead_hits_df, filtered_fn)]:\n",
        "                d.to_excel(f\"/content/drive/MyDrive/{name}\", index=False)\n",
        "\n",
        "        # Download Files\n",
        "        for f_name in [excel_fn, physchem_fn, filtered_fn, txt_fn]:\n",
        "            files.download(f_name)\n",
        "\n",
        "        print(f\"\\n‚úÖ PROCESS COMPLETE. Created 4 files.\")\n",
        "        print(f\"üíé Filtered 'Lead-Like' Hits Found: {len(lead_hits_df)}\")\n",
        "\n",
        "        # Visual Summary\n",
        "        img = Draw.MolsToGridImage([Chem.MolFromSmiles(s) for s in lead_hits_df['SMILES'].head(12)],\n",
        "                                   molsPerRow=4, legends=list(lead_hits_df['ID'].head(12)))\n",
        "        display(img)"
      ]
    }
  ]
}